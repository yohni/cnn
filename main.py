# -*- coding: utf-8 -*-
"""tutorial

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fS35fGBDuQqTBcIT02ISZlgCYogZz_6r
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

from torchvision import datasets, transforms

from PIL import Image
import matplotlib.image as mpimg
import matplotlib.pyplot as plt

#GPU seed
torch.manual_seed(11)
torch.cuda.manual_seed_all(11)

def im_convert(tensor):
  image = tensor.to("cpu").clone().detach()
  image = image.numpy().squeeze()
  
  return image
  
def printthis(image_tensor):
  plt.imshow(im_convert(image_tensor))
  plt.show()

class Net(nn.Module):
  def __init__(self):
    super(Net, self).__init__()
    self.conv1 = nn.Conv2d(1,10,5,1)
    self.conv2 = nn.Conv2d(10,10,5,1)
    self.pool = nn.MaxPool2d(2)
    self.fc1 = nn.Linear(4*4*10,200)
    self.fc2 = nn.Linear(200,10)
    
  def forward(self,x):
    x = F.relu(self.conv1(x))
    x = self.pool(x)
    x = F.relu(self.conv2(x))
    x = self.pool(x)
    x = x.view(-1, 4*4*10)
    x = F.relu(self.fc1(x))
    x = self.fc2(x)
    
    return x

train_loader = torch.utils.data.DataLoader(
    datasets.MNIST('../data', train=True, download=True,
                  transform=transforms.Compose([
                      transforms.ToTensor()
                  ])),
                   batch_size=100, shuffle=True
)

test_loader = torch.utils.data.DataLoader(
    datasets.MNIST('../data', train=False, download=True,
                  transform=transforms.Compose([
                      transforms.ToTensor()
                  ])),
                   batch_size=100, shuffle=True
)

images = train_loader.dataset[0]

n_data_train = len(train_loader.dataset)
n_data_test = len(test_loader.dataset)

model = Net().cuda()

optimizer = optim.SGD(model.parameters(), lr=0.01)
criterion = nn.CrossEntropyLoss()

ep_acc_train = []
ep_acc_test = []
ep_loss_train = []
ep_loss_test = []
for i in range(1,10):
  total_loss_train = 0
  total_acc_train = 0
  for images, labels in train_loader:
    images = images.cuda()
    labels = labels.cuda()
    
    optimizer.zero_grad()
    output = model(images)
    
    loss = criterion(output, labels)
    loss.backward()
    optimizer.step()
    
    total_loss_train += loss.item()
    total_acc_train += torch.sum(torch.max(output,dim=1)[1]==labels).item()*1.0
    
  ep_acc_train.append(total_acc_train/n_data_train*100.0)  
  ep_loss_train.append(total_loss_train/n_data_train)
  
  total_loss_test = 0
  total_acc_test = 0
  for images_test, labels_test in test_loader:
    images_test = images_test.cuda()
    labels_test = labels_test.cuda()
    
    with torch.no_grad():
      output_test = model(images_test)
    
      loss_test = criterion(output_test, labels_test)
    
      total_loss_test += loss_test.item()
      total_acc_test += torch.sum(torch.max(output_test,dim=1)[1]==labels_test).item()*1.0
  
  ep_acc_test.append(total_acc_test/n_data_test*100.0)
  ep_loss_test.append(total_loss_test/n_data_test)

plt.figure(1)
plt.plot(ep_loss_train,'r-', label='train')
plt.plot(ep_loss_test,'b-', label='validation')
plt.xlabel('epoch')
plt.ylabel('error')
plt.legend(loc='upper right')

plt.figure(2)
plt.plot(ep_acc_train,'r-', label='train')
plt.plot(ep_acc_test,'b-', label='validation')
plt.xlabel('epoch')
plt.ylabel('accuracy')
plt.legend(loc='upper right')

plt.show()